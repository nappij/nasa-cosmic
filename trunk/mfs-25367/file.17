C
      SUBROUTINE LINEAR (X, CLASS, W, MOC, S, Y, B, A2)
C
C  COMPUTE LINEAR DISCRIMINANTS AND TEST USING TRAINING SAMPLES
C
      DIMENSION X(1), W(1), MOC(1), S(1), Y(1), B(1), A2(1)
      DOUBLE PRECISION CLASS(MM)
      LOGICAL ORDER
      COMMON /DISTNC/ DNW, D, ORDER
      COMMON /CLSSFR/ NN, MM, NRECS, NSAMP, NSC
C
C  COMPUTE THE ORDER OF DISCRIMINANT TESTING AND LINEAR DISCRIMINANTS
      NN1 = NN + 1
      MM1 = MM - 1
      DO 100 NC=1,MM
  100 MOC(NC) = NC
C
C     FIND CLASS WITH MAXIMUM DISTANCE FROM HYPERPLANE
      DO 1000 NW1=1,MM1
      WRITE (6,5010)
      IF (NW1.EQ.MM1) GO TO 1000
      WRITE (6,5000)
      ORDER = .TRUE.
      DMAX = -1.0 E 50
      DO 500 NC1=NW1,MM
      CALL SNOPAL (X, CLASS, W, MOC, S, Y, B, A2, NW1, NN1)
      DD = DNW + D
      WRITE (6,5020) CLASS(MOC(NW1)), DNW, D, DD
      IF (DD.LT.DMAX) GO TO 150
      DMAX = DD
      NCLASS = NC1
C
C     ROTATE CLASS NUMBERS IN ARRAY 'MOC'
  150 MSAVE = MOC(NW1)
      DO 200 NC=NW1,MM1
  200 MOC(NC) = MOC(NC+1)
      MOC(MM) = MSAVE
  500 CONTINUE
C
C     PLACE DISCRIMINATED CLASS NUMBER AT TOP OF ARRAY 'MOC'
      ITEMP = MOC(NW1)
      MOC(NW1) = MOC(NCLASS)
      MOC(NCLASS) = ITEMP
      ORDER = .FALSE.
 1000 CALL SNOPAL (X, CLASS, W, MOC, S, Y, B, A2, NW1, NN1)
C
C  TEST THE CLASSIFICATION OF THE TRAINING SAMPLES
      CALL NTEST (X, CLASS, W, MOC)
      RETURN
C
 5000 FORMAT (20X,31('*')/20X,'* DATA - HYPERPLANE DISTANCES *'/20X,
     .31('*'))
 5010 FORMAT ('1')
 5020 FORMAT (/A30,5X,'OTHER',5X,'TOTAL'/20X,3F10.4)
      END
C
      SUBROUTINE SNOPAL (X, CLASS, W, MOC, S, Y, B, A2, NW1, NN1)
C
C  SUPERVISED NON-PARAMETRIC LEARNING
C
      LOGICAL*1 X(NN,MM,NSC)
      DIMENSION W(NN1,1), MOC(MM), Y(1), B(1), A2(NN1,1)
      DOUBLE PRECISION CLASS(MM), S(NN1,NN1), DET
      INTEGER SIJ
      LOGICAL TEST, ORDER
      COMMON /DISTNC/ DNW, D, ORDER
      COMMON /CLSSFR/ NN, MM, NRECS, NSAMP, NSC
      DATA DELTA /0.01/
C
C  COMPUTE INVERSE OF A(TRANSPOSE) A WHERE 'A' IS AUGMENTED MATRIX
C  OF SAMPLES
C
      DO 130 I=1,NN1
      DO 130 J=1,I
      SIJ = 0
C
      DO 70 NC1=NW1,MM
      NC = MOC(NC1)
      IF (I.EQ.NN1) GO TO 133
C
C     INDEX I NOT EQUAL TO NO. OF BANDS + 1
      DO 132 NS1=1,NSC
  132 SIJ = SIJ + X(I,NC,NS1)*X(J,NC,NS1)
      GO TO 70
C
C     INDEX I EQUAL TO NO. OF BANDS + 1
  133 IF (J.EQ.NN1) GO TO 70
      DO 134 NS1=1,NSC
  134 SIJ = SIJ + X(J,NC,NS1)
   70 CONTINUE
C
      S(I,J) = SIJ
  130 S(J,I) = SIJ
      S(NN1,NN1) = NSC * (MM-NW1+1)
C
      CALL GASINV (S, NN1, DET)
C
C     INITIALIZE W, Y, B, AND A2 ARRAYS
      DO 1112 NFA=1,NN1
 1112 W(NFA,NW1) = 0.0
      NST2 = 0
      DO 1110 NC1=NW1,MM
      NC = MOC(NC1)
      DO 1110 NS1=1,NSC
      NST2 = NST2 + 1
      Y(NST2) =-1.0
      B(NST2) = 1.0
      DO 1110 I=1,NN1
      A2(I,NST2) = S(I,NN1)
      DO 1110 K=1,NN
 1110 A2(I,NST2) = A2(I,NST2) + S(I,K)*X(K,NC,NS1)
C
C  DO NI ITERATIONS OF THE HO-KASHYAP ALGORITHM, UNLESS ALL COEFFICIENTS
C  CHANGE BY LESS THAN 1 PERCENT
C
      NI = 50
      IF (ORDER) NI = 10
      NW2 = NW1 + 1
      NW = MOC(NW1)
      IF (.NOT.ORDER) WRITE (6,102) NW, CLASS(NW), CLASS(NW)
      DO 1040 INDEX=1,NI
      TEST = .TRUE.
C
C     COMPUTE NN1 COEFFICIENTS FOR CLASS NW AND STORE IN W
      DO 1101 I=1,NN1
      W0 = W(I,NW1)
C
C     USE SAMPLES FROM CLASS NW
      DO 2101 J=1,NSC
 2101 W(I,NW1) = W(I,NW1) + A2(I,J)*ABS(Y(J))
C
C     LOOP OVER REMAINING CLASSES
      J = NSC
      DO 2000 NC1=NW2,MM
      DO 2000 NS1=1,NSC
      J = J + 1
 2000 W(I,NW1) = W(I,NW1) - A2(I,J)*ABS(Y(J))
C
C     TEST COEFFICIENTS FOR CHANGE
      IF (ABS(W(I,NW1)-W0).GT.ABS(DELTA*W0)) TEST = .FALSE.
 1101 CONTINUE
C
C  COMPUTE NEW DISCRIMINANT VALUES AND CLASSIFICATION ERRORS
C
C     DO FOR CLASS NW
      NERR1 = 0
      DNW = 0.0
      DO 1004 I=1,NSC
      IF (Y(I).GT.0.0) B(I) = B(I) + 2.0*Y(I)
      Y(I) = W(NN1,NW1)
      DO 1141 NF2=1,NN
 1141 Y(I) = Y(I) + W(NF2,NW1)*X(NF2,NW,I)
      IF (Y(I).LE.0.0) NERR1 = NERR1 + 1
      DNW = DNW + Y(I)
 1004 Y(I) = Y(I) - B(I)
C
C     LOOP OVER REMAINING CLASSES
      I = NSC
      NERR2 = 0
      D = 0.0
      DO 1005 NC1=NW2,MM
      NC = MOC(NC1)
      DO 1000 NS1=1,NSC
      I = I + 1
      IF (Y(I).GT.0.0) B(I) = B(I) + 2.0*Y(I)
      Y(I) = W(NN1,NW1)
      DO 145 NF2=1,NN
  145 Y(I) = Y(I) + W(NF2,NW1)*X(NF2,NC,NS1)
      IF (Y(I).GT.0.0) NERR2 = NERR2 + 1
      D = D + Y(I)
 1000 Y(I) = -Y(I) - B(I)
 1005 CONTINUE
      DNW = DNW / NSC
      D = -D / (NSC*(MM-NW1))
C
      IF (.NOT.ORDER) WRITE (6,100) INDEX, NERR1, NERR2, (W(NFA,NW1),
     .NFA=1,NN1)
      IF (TEST) GO TO 1010
 1040 CONTINUE
 1010 NERR = NERR1 + NERR2
      IF (.NOT.ORDER) WRITE (6,220) NERR
C
      IF (NW1.NE.MM-1) RETURN
      WRITE (6,216)
      MM1 = MM - 1
      DO 1220 NW=1,MM1
 1220 WRITE (6,101) MOC(NW), CLASS(MOC(NW)), (W(NFA,NW), NFA=1,NN1)
      WRITE (6,101) MOC(MM), CLASS(MOC(MM))
      RETURN
C
  100 FORMAT (I8,I11,I8,4X,1P7E14.3/(31X,1P7E14.3))
  101 FORMAT (/I13,A10,10X,1P7E14.3/(33X,1P7E14.3))
  102 FORMAT (//22X,22('*')/22X,'* CLASS',I3,A10,' *'/22X,22('*')//' ITE
     .RATION NO.',5X,'ERRORS',10X,'LINEAR DISCRIMINANT COEFFICIENTS'/
     .A22,'  OTHER'/)
  216 FORMAT ('1'/10X,'ORDERED CLASSES',20X,'ELEMENTS OF THE DISCRIMINAN
     .T VECTOR'/10X,15('*'),20X,35('*')/)
  220 FORMAT (/7X,'TOTAL ERRORS',I5)
      END
C
      SUBROUTINE NTEST (X, CLASS, W, MOC)
C
C  CLASSIFIES KNOWN DATA SAMPLES - NONPARAMETRIC CLASSIFICATION
C
      LOGICAL*1 X(NN,MM,NSC), ICLASS
      DIMENSION W(1), MOC(1), KS(20)
      DOUBLE PRECISION CLASS(MM)
      COMMON /CLSSFR/ NN, MM, NRECS, NSAMP, NSC
C
      NN1 = NN + 1
      MM1 = MM - 1
      WRITE(6,2008) CLASS
      TE = 0.0
C
      DO 1500 NC=1,MM
      DO 1109 I=1,MM
 1109 KS(I) = 0
C
      DO 1400 NS1 = 1,NSC
 1400 CALL NOPACA (X(1,NC,NS1), ICLASS, KS, W, MOC, 1, NN1, MM1)
C
      EFF = 100.0 * KS(NC) / NSC
      WRITE (6,2009) NC, CLASS(NC), NSC, KS(NC), EFF, (KS(N), N=1,MM)
 1500 TE = TE + EFF
      AVE = TE / FLOAT(MM)
      WRITE (6,2104) AVE
      RETURN
C
 2008 FORMAT ('1'/30X,29('*')/30X,'* RESULTS OF CLASSIFICATION *'/30X,'*
     .     TRAINING SAMPLES      *'/30X,29('*')///14X,'NUMBER OF  NUMBER
     .     PERCENT     NUMBER OF SAMPLES CLASSIFIED AS'/6X,'CLASS    SAM
     .PLES   CORRECT    CORRECT',10A9/(43X,10A9))
 2009 FORMAT (/I4,A9,I7,I11,F10.1,10I9/(41X,10I9))
 2104 FORMAT (//30X,18HAVERAGE ACCURACY =,F6.1,8H PERCENT/30X,32(1H*))
      END
C
      SUBROUTINE NCLASS (S, MCLASS, CLASS, W, MOC)
C
C NONPARAMETRIC CLASSIFICATION
C CLASSIFIES DATA SAMPLES AND STORES CLASSIFICATION RESULTS ON TAPE
C
      LOGICAL*1 S(NN,NSAMP), MCLASS(NSAMP)
      DIMENSION W(1), MOC(1), KS(20)
      DOUBLE PRECISION CLASS(MM)
      COMMON /CLSSFR/ NN, MM, NRECS, NSAMP, NSC
C
      NN1 = NN + 1
      MM1 = MM - 1
      DO 100 NC=1,MM
  100 KS(NC) = 0
      NTOT = NSAMP * NRECS
C
      DO 12 NREC=1,NRECS
      READ (10) S
      CALL NOPACA (S, MCLASS, KS, W, MOC, NSAMP, NN1, MM1)
   12 WRITE (11) MCLASS
C
      WRITE (6,2010)
      DO 200 NC=1,MM
      PCT = 100.0 * KS(NC) / NTOT
  200 WRITE (6,2011) NC, CLASS(NC), KS(NC), PCT
      WRITE (6,2012) NTOT
      RETURN
C
 2010 FORMAT ('1'/30X,29('*')/30X,'* RESULTS OF CLASSIFICATION *'/30X,
     .'*',7X,'DATA SAMPLES',8X,'*'/30X,29('*')///20X,'CLASS',15X,'SAMPLE
     .S',15X,'PERCENT'/20X,5('*'),2(15X,7('*')))
 2011 FORMAT (/I17,A9,I20,F22.2)
 2012 FORMAT (/13X,13HTOTAL SAMPLES,I20/13X,13(1H*))
      END
C
      SUBROUTINE NOPACA (X, NW, KS, W, MOC, NSS, NN1, MM1)
C
C NON-PARAMETRIC CLASSIFICATION OF A STRING OF NSS FEATURE VECTORS
C USING PRE-LEARNED LINEAR DISCRIMINANT FUNCTIONS
C
      LOGICAL*1 X(NN,NSS), NW(NSS)
      DIMENSION W(NN1,MM1), MOC(MM), KS(MM), X1(20)
      COMMON /CLSSFR/ NN, MM, NRECS, NSAMP, NSC
C
C     COMPUTE VALUES OF DISCRIMINANT FUNCTION AND TRANSFER IF POSITIVE
      DO 20 NS1=1,NSS
      DO 5 NF1=1,NN
    5 X1(NF1) = X(NF1,NS1)
C
      DO 1 NW1=1,MM1
      G = W(NN1,NW1)
        DO 2 NF1=1,NN
    2   G = G + W(NF1,NW1)*X1(NF1)
      IF (G.GT.0.0) GO TO 3
    1 CONTINUE
      NW1 = MM
C
    3 NC=MOC(NW1)
      KS(NC) = KS(NC)+1
      NW(NS1) = NC
   20 CONTINUE
      RETURN
      END
C
      SUBROUTINE GASINV (A, N, DET)
C
C  COMPUTE INVERSE AND DETERMINANT OF SYMMETRIC MATRIX A
C
      DOUBLE PRECISION A(N,N), DET, TEST, TEMP, FAC, W, D
      DIMENSION IORD(20)
      DET#1.
      DO 1 I#1,N
 1    IORD%I<#I
      DO 2 K#1,N
      IF %K.EQ.N< GO TO 3
      TEST = DABS(A(K,K))
      KP1#K&1
      L#K
      DO 4 I#KP1,N
      IF (TEST.GE.DABS(A(I,K))) GO TO 4
      TEST = DABS(A(I,K))
      L#I
 4    CONTINUE
      IF %L.EQ.K< GO TO 3
      DO 5 J#1,N
      TEMP#A%L,J<
      A%L,J<#A%K,J<
 5    A%K,J<#TEMP
      J#IORD%L<
      IORD%L<#IORD%K<
      IORD%K<#J
      DET # -DET
 3    DET#DET*A%K,K<
      A%K,K<#1./A%K,K<
      DO 6 J#1,N
      IF %J.EQ.K< GO TO 6
      A%K,J<#A%K,J<*A%K,K<
 6    CONTINUE
      DO 7 I#1,N
      IF %I.EQ.K< GO TO 7
      FAC#A%I,K<
      A%I,K<#-A%I,K<*A%K,K<
      DO 8 J#1,N
      IF %J.EQ.K< GO TO 8
      W = FAC * A(K,J)
      D = A(I,J) - W
      IF (DABS(D).LT.0.00001*DABS(W)) D = 0.0
      A%I,J<#D
 8    CONTINUE
 7    CONTINUE
 2    CONTINUE
      NM1#N-1
      DO 9 J#1,NM1
 12   CONTINUE
      IF %IORD%J<.EQ.J< GO TO 9
      K#IORD%J<
      IORD%J<#IORD%K<
      IORD%K<#K
      DO 10 I#1,N
      TEMP#A%I,J<
      A%I,J<#A%I,K<
 10   A%I,K<#TEMP
      GO TO 12
 9    CONTINUE
      DO 15 I=2,N
      I1 = I - 1
      DO 15 J=1,I1
      A(I,J) = (A(I,J)+A(J,I))/2.0
   15 A(J,I) = A(I,J)
      RETURN
      END
